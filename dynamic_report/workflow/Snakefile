# This subpipeline is run when the main asscom2 pipeline is done. 
# This subpipeline checks if the void report flag (.asscom2_void_report.flag) file has been modified by a rule in the parent pipeline. If so, the report will be rendered.


__author__ = 'Carl M. Kobel'

# These could be written to the config file when running the main pipeline.
output_directory = config['output_directory'] # E.g. results_ac2
base_variable = config['base_variable'] # E.g. path/to/installation/of/assemblycomparator2
batch_title = config['batch_title'] # E.g. E._faecium 
__version__ = config['__version__']

containerized: f"docker://cmkobel/assemblycomparator2:v{__version__}"
#containerized: f"docker://cmkobel/assemblycomparator2:latest" # DEBUG

print('report subpipeline: output_directory:', output_directory)
print('report subpipeline: base_variable:', base_variable)


try: 
    os.mkdir(f"{output_directory}/tables") # When using apptainer, I've had some problems with "mkdir: cannot create directory ‘/home/thylakoid/pnytera’: Read-only file system". I think moving this command out of the shell script may solve the problem?
except:
    pass


def should_run(wildcards):
    if os.path.isfile(f"{output_directory}/metadata.tsv") and os.path.isfile(f"{output_directory}/.asscom2_void_report.flag"):
        #return {"flag": f"{output_directory}/.asscom2_void_report.flag", "metadata": f"{output_directory}/metadata.tsv"}
        return [f"{output_directory}/report_{batch_title}.html"]
    else:
        return [] # empty list, no running requirement.


def text_box(title_text):
    #setup
    padding = "   "
    greeting = f" The {title_text} report has been rendered. "
    greeting_len = len(greeting) # minus 2 is the extra padding.
    
    #build
    box = ""
    box += "\n" + padding + " " + greeting_len * "-"
    box += "\n" + padding + "<" + greeting + ">"
    box += "\n" + padding + " " + greeting_len * "-"
    return box
    

# The report should always run locally no matter the queuing system available.
localrules: dynamic_report

rule all:
    input: 
        should_run

# Runs on the front end because it is quick anyway.
# This rule needs to be inside its own snakefile, as it is the only way I can run it on onerror/onsuccess
rule dynamic_report:
    input:
        #unpack(should_run)
        flag = f"{output_directory}/.asscom2_void_report.flag", # This is the file being touched when void_report is called in every rule in the parent pipeline.
        metadata = f"{output_directory}/metadata.tsv", # Without the metadata, the report doesn't make sense. Most segments use the metadata to translate sample names from files paths.
    conda: "envs/r-markdown.yaml"
    params: 
        base_variable = base_variable,
        output_directory = output_directory,
        batch_title = batch_title,
        end_script = f"{base_variable}/dynamic_report/workflow/scripts/report_end_script.sh",
        text_box = text_box(batch_title)
    output: 
        html = f"{output_directory}/report_{batch_title}.html",
    #output: expand("{output_directory}/report_{batch_title}.html", output_directory = output_directory, batch_title = batch_title)
    
    shell: """	    
        
        # Rmarkdown render() insists on writing the output relative to the path of the template. Thus we must copy the template to the local system (.writable_template_copy). In some cases, the user won't have write access to the code base path so having a writable copy (below the current working directory) is a reasonable workaround.
        
        # First remove possible old directory
        test -d .writable_template_copy/ && rm -r .writable_template_copy/
        cp -r {base_variable}/dynamic_report/workflow/scripts .writable_template_copy # This one fails when using apptainer. Maybe I just need to bind it.
        
        # Is this still used?
        # mkdir -p {params.output_directory}/tables # Directory for the rmarkdown to write its compiled tables to.
    
        Rscript -e '
            # Set parameters
            base_variable = "{params.base_variable}"; output_directory = "{params.output_directory}"; batch_title = "{params.batch_title}"; version_string = "{__version__}"; current_dir = getwd()
            
            # Render report
            rmarkdown::render(
                input = ".writable_template_copy/report_template.rmd", 
                output_format = "html_document",
                output_file = paste0(current_dir, "/{params.output_directory}/report_{batch_title}.html"),
                knit_root_dir = current_dir
            )'

        # Clean up 
        rm -r .writable_template_copy # Problem is that this file is only removed if pipeline finishes.

        # End script
        test -f "{params.end_script}" && echo "running end script" && . {params.end_script} {batch_title} {output_directory}/report_{batch_title}.html 
        
        # Print the ass. Thanks to George Taiaroa.
        echo "{params.text_box}"
        cat {base_variable}/resources/ass.txt
    """


onsuccess:
    shell(f"""rm .report_config.yaml""")


# Note: The stderr/out from rule report should not be shown on screen as it problematically wipes possible interesting fail-outputs from the main asscom2 pipeline.
