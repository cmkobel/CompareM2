# This subpipeline is run when the main comparem2 pipeline is done. 
# This subpipeline checks if the void report flag (.comparem2_void_report.flag) file has been modified by a rule in the parent pipeline. If so, the report will be rendered.

import pandas as pd

__author__ = 'Carl M. Kobel'

# These could be written to the config file when running the main pipeline.
output_directory = config['output_directory'] # E.g. results_comparem2
base_variable = config['base_variable'] # E.g. path/to/installation/of/comparem2
batch_title = config['batch_title'] # E.g. E._faecium 
__version__ = config['__version__']

containerized: f"docker://cmkobel/comparem2:v{__version__}"
#containerized: f"docker://cmkobel/comparem2:latest" # DEBUG

print('report subpipeline: output_directory:', output_directory)
print('report subpipeline: base_variable:', base_variable)


try: 
    os.mkdir(f"{output_directory}/tables") # When using apptainer, I've had some problems with "mkdir: cannot create directory ‘/home/thylakoid/pnytera’: Read-only file system". I think moving this command out of the shell script may solve the problem?
except:
    pass


def should_run(wildcards):
    """ Returns the final output file (report .html) in case the metadata and exists and the report is voided. Otherwise it returns an empty list and no jobs are run.
    """
    if os.path.isfile(f"{output_directory}/metadata.tsv") and os.path.isfile(f"{output_directory}/.comparem2_void_report.flag"):
        return [f"{output_directory}/report_{batch_title}.html"]
    else:
        return [] # empty list, no running requirement.


def text_box(title_text):
    """ Helper function to build a text box of dynamic length.
    """
    padding = "   "
    greeting = f" The {title_text} report has been rendered. "
    greeting_len = len(greeting) 
    
    box = ""
    box += "\n" + padding + " " + greeting_len * "-"
    box += "\n" + padding + "<" +   greeting   + ">"
    box += "\n" + padding + " " + greeting_len * "-"
    return box
    

# The report should always run locally no matter the queuing system available.
localrules: dynamic_report

rule all:
    input: 
        should_run

# Runs on the front end because it is quick anyway.
# This rule needs to be inside its own snakefile, as it is the only way I can run it on onerror/onsuccess
rule dynamic_report:
    input:
        flag = f"{output_directory}/.comparem2_void_report.flag", # This is the file being touched when void_report is called in every rule in the parent pipeline.
        metadata = f"{output_directory}/metadata.tsv", # Without the metadata, the report doesn't make sense. Most segments use the metadata to translate sample names from files paths.
    conda: "envs/r-markdown.yaml"
    params: 
        base_variable = base_variable,
        output_directory = output_directory,
        batch_title = batch_title,
        end_script = f"{base_variable}/dynamic_report/workflow/scripts/report_end_script.sh",
        text_box = text_box(batch_title)
    output: 
        html = f"{output_directory}/report_{batch_title}.html",
    shell: """	    
        
        # Rmarkdown render() insists on writing the output relative to the path of the template. Thus we must copy the template to the local system (.writable_template_copy). In some cases, the user won't have write access to the code base path so having a writable copy (below the current working directory) is a reasonable workaround.
        
        # First remove possible old directory
        test -d .writable_template_copy/ && rm -r .writable_template_copy/
        cp -r {base_variable}/dynamic_report/workflow/scripts .writable_template_copy # This one fails when using apptainer. Maybe I just need to bind it.
        
        # Is this still used?
        # mkdir -p {params.output_directory}/tables # Directory for the rmarkdown to write its compiled tables to.
    
        Rscript -e '
            # Set parameters
            base_variable = "{params.base_variable}"; output_directory = "{params.output_directory}"; batch_title = "{params.batch_title}"; version_string = "{__version__}"; current_dir = getwd()
            
            # Render report
            rmarkdown::render(
                input = ".writable_template_copy/report_template.rmd", 
                output_format = "html_document",
                output_file = paste0(current_dir, "/{params.output_directory}/report_{batch_title}.html"),
                knit_root_dir = current_dir
            )'

        # Clean up 
        rm -r .writable_template_copy # Problem is that this file is only removed if pipeline finishes. Should it be removed by onerror?

        # End script
        test -f "{params.end_script}" && echo "running end script" && . {params.end_script} {batch_title} {output_directory}/report_{batch_title}.html || true
        
    """
    

def format_sections():
    """This function reads the sections tsv and formats in a nice way (by removing the terminal-incompatible emoji's).
    """
    file = f"{output_directory}/tables/{batch_title}__sections.tsv"
    if os.path.exists(file): 
        df_sections = pd.read_csv(file, sep = "\t").rename(columns={"render": "render_emoji"})
        df_sections['render'] = [i.encode('ascii', errors='ignore').decode() for i in df_sections['render_emoji']]
        return df_sections[["section", "n / expected", "render"]].to_string(index = False)
    else: # If something messes up the report so bad that this file is not written. 
        return f"(could not read {file})"


onsuccess:
    shell(f"""rm .report_config.yaml""")
    print(f"""
The '{batch_title}' report has been rendered to {rules.dynamic_report.output}
Below is an overview of which sections have been rendered.

  Report sections
  ---------------""")
    print(format_sections())
    print("//")
    

# Note: The stderr/out from rule report should not be shown on screen as it problematically wipes possible interesting fail-outputs from the main comparem2 pipeline.
